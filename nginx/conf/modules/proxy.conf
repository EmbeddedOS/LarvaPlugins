# The ngx_http_proxy_module module allows passing requests to another server.

# By default, NGINX redefines two header fields in proxied requests, “Host” and 
# “Connection”, and eliminates the header fields whose values are empty strings.
# “Host” is set to the $proxy_host variable, and “Connection” is set to close.
# We need to change these header fields:
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header X-Forwarded-Proto $scheme;

# Enable SNI.
proxy_ssl_name $host;
proxy_ssl_server_name on;

proxy_ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;

map $http_upgrade $connection_upgrade {
  	default upgrade;
    ''      '';
}

# Keepalive connections can have a major impact on performance by reducing 
# the CPU and network overhead needed to open and close connections. To enable 
# keepalive connections to upstream servers you must also include the following 
# directives in the configuration:
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection $connection_upgrade;
proxy_http_version 1.1;


# Configuring Buffers.
# By default NGINX buffers responses from proxied servers. A response is stored 
# in the internal buffers and is not sent to the client until the whole response 
# is received. Buffering helps to optimize performance with slow clients, which 
# can waste proxied server time if the response is passed from NGINX to the 
# client synchronously. However, when buffering is enabled NGINX allows the 
# proxied server to process responses quickly, while NGINX stores the responses 
# for as much time as the clients need to download them.

# The `proxy_buffers` directive controls the size and the number of buffers allocated 
# for a request. The first part of the response from a proxied server is stored in 
# a separate buffer, the size of which is set with the `proxy_buffer_size` directive. 
# This part usually contains a comparatively small response header and can be made
# smaller than the buffers for the rest of the response.

# If buffering is disabled, the response is sent to the client synchronously while it 
# is receiving it from the proxied server. This behavior may be desirable for fast 
# interactive clients that need to start receiving the response as soon as possible.
proxy_buffering on;

# When request buffering is enabled, the entire request body is read from the client before 
# sending the request to a proxied server.
# When buffering is disabled, the request body is sent to the proxied server immediately as
# it is received. In this case, the request cannot be passed to the next server if nginx 
# already started sending the request body.
proxy_request_buffering on;

# Sets the size of the buffer used for reading the first part of the response received from 
# the proxied server. This part usually contains a small response header. By default, 
# the buffer size is equal to one memory page. This is either 4K or 8K, depending on a 
# platform. It can be made smaller, however.
proxy_buffer_size 16k;
proxy_buffers 8 16k;

# NGINX Content Caching.
# Cache both static and dynamic content from your proxied web and application servers, 
# to speed delivery to clients and reduce the load on the servers. When caching is enabled,
# NGINX saves responses in a disk cache and uses them to respond to clients without having
# to proxy requests for the same content every time.

# Proxy caches such as NGINX are relatively free to interpret how strictly they will comply 
# with those headers. Clearly they shouldn’t cache something which is not cacheable, but of
# course they’ve got no obligations to cache something if the origin server says it is
# cacheable.
# The basic NGINX behavior is to cache all GET and HEAD requests that are indicated by the
# origin server as being cacheable, provided there are no `Set-Cookie` headers in the response.
# That’s because Set-Cookie headers typically include unique data specific to each request 
# and by default it wouldn’t be appropriate to cache that value.
proxy_ignore_headers "Set-Cookie";
proxy_cache_methods GET HEAD;

# Sometimes you may not cache content that the origin server says is cacheable, or you may want
# to ensure that you bypass the version of content stored in NGINX. The `proxy_cache_bypass` 
# and `proxy_no_cache` directives give you that degree of control.

# Defines conditions under which the response will not be taken from a cache. If at least one 
# value of the string parameters is not empty and is not equal to “0” then the response will not
# be taken from the cache:
proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment;

# Defines conditions under which the response will not be saved to a cache. If at least one
# value of the string parameters is not empty and is not equal to “0” then the response will
# not be saved:
proxy_no_cache $http_authorization;

# Enables revalidation of expired cache items using conditional requests with the 
# “If-Modified-Since” and “If-None-Match” header fields.
proxy_cache_revalidate on;

# Sets the number of requests after which the response will be cached.
proxy_cache_min_uses 1;

# Determines in which cases a stale cached response can be used during communication with 
# the proxied server.
proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
proxy_cache_background_update on;

# When enabled, only one request at a time will be allowed to populate a new cache element
# identified according to the proxy_cache_key directive by passing a request to a proxied server.
# Other requests of the same cache element will either wait for a response to appear in the
# cache or the cache lock for this element to be released, up to the time set by the 
# `proxy_cache_lock_timeout` directive.
proxy_cache_lock off;

# ngx_cache_purge is nginx module which adds ability to purge content from FastCGI, proxy, SCGI
# and uWSGI caches. A purge operation removes the content with the same cache key as the purge 
# request has. feature:
# 	purge all: Include option to purge all the cached files This option can be slow if a 
#		   lot of content is cached, or if the storage used for the cache is slow. 
# 		   But you really should be using RAM as your cache storage. e.g: 
# 		   `proxy_cache_purge PURGE purge_all from 127.0.0.1;`
# 	partial keys: Support partial keys to purge multiple keys. Put an '*' at the end of 
#		      your purge cache URL, e.g: `curl -X PURGE https://sitetest.com/*`
# Repository: https://github.com/nginx-modules/ngx_cache_purge

# Sets a response type of purging result.
cache_purge_response_type text;


# Sets the path and other parameters of a cache. Cache data are stored in files. The file name 
# in a cache is a result of applying the MD5 function to the cache key. In addition, all active
# keys and information about data are stored in a shared memory zone, whose `name` and `size` are 
# configured by the `keys_zone` parameter. One megabyte zone can store about 8 thousand keys.

# Cached data that are not accessed during the time specified by the inactive parameter get 
# removed from the cache regardless of their freshness. By default, inactive is set to 10 minutes.
proxy_cache_path /data/nginx/cache/ keys_zone=caching_server_key200m
                                   levels=1:2
                                   inactive=24h
                                   max_size=5g;

proxy_cache caching_server_key;

map $http_user_agent $user_agent_device {
	~*(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge\ |maemo|midp|mmp|mobile.+firefox|netfront|opera\ m(ob|in)i|palm(\ os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows\ ce|xda|xiino/i 'mobile';
   	~*android|ipad|playbook|silk/i 'tablet';
    	default 'desktop';
}
# Hash proxy key following arguments:
# http-scheme | server-name | server-port | request-uri | user-agent-device
proxy_cache_key "$scheme$server_name$server_port$request_uri$user_agent_device";
